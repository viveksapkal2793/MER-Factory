# ğŸ‘‰ğŸ» MER-Factory ğŸ‘ˆğŸ»

<p align="left">
        ä¸­æ–‡</a>&nbsp ï½œ &nbsp<a href="README.md">English</a>
</p>
<br>

<p align="center">
  <strong>æ‚¨çš„å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«ä¸æ¨ç†ï¼ˆMERRï¼‰æ•°æ®é›†è‡ªåŠ¨åŒ–å·¥å‚ã€‚</strong>
</p>
<p align="center">
  <a href="https://lum1104.github.io/MER-Factory/" target="_blank">ğŸ“– é¡¹ç›®æ–‡æ¡£</a>
</p>

<p align="center"> <img src="https://img.shields.io/badge/Task-Multimodal_Emotion_Reasoning-red"> <img src="https://img.shields.io/badge/Task-Multimodal_Emotion_Recognition-red"> <img src="https://zenodo.org/badge/1007639998.svg" alt="DOI"> </p>

<p align="center"> <img src="docs/assets/logo.svg" width="400"> </p>

<!-- <p align="center">
  <a href="https://lum1104.github.io/MER-Factory/">
    <img src="https://svg-banners.vercel.app/api?type=origin&text1=MER-Factory%20ğŸ§°&text2=âœ¨%20å¤šæ¨¡æ€æƒ…ç»ªè¯†åˆ«æ¨ç†%20(MERR)%20æ•°æ®é›†å·¥å‚&width=800&height=200" alt="MER-Factory Banner">
  </a>
</p> -->

## ğŸš€ é¡¹ç›®è·¯çº¿å›¾

MER-Factory æ­£åœ¨ç§¯æå¼€å‘ä¸­ï¼Œæ–°åŠŸèƒ½ä¼šå®šæœŸæ·»åŠ  - æŸ¥çœ‹æˆ‘ä»¬çš„[è·¯çº¿å›¾](https://github.com/Lum1104/MER-Factory/wiki)ï¼Œæ¬¢è¿è´¡çŒ®ï¼

## ç›®å½•

- [Pipeline ç»“æ„](#pipeline-ç»“æ„)
- [ç‰¹æ€§](#ç‰¹æ€§)
- [å®‰è£…](#å®‰è£…)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
  - [åŸºæœ¬å‘½ä»¤ç»“æ„](#åŸºæœ¬å‘½ä»¤ç»“æ„)
  - [ç¤ºä¾‹](#ç¤ºä¾‹)
  - [å‘½ä»¤è¡Œé€‰é¡¹](#å‘½ä»¤è¡Œé€‰é¡¹)
  - [å¤„ç†ç±»å‹](#å¤„ç†ç±»å‹)
- [æ¨¡å‹æ”¯æŒ](#æ¨¡å‹æ”¯æŒ)
  - [æ¨¡å‹æ¨è](#æ¨¡å‹æ¨è)
- [å¼•ç”¨](#å¼•ç”¨)

## Pipeline ç»“æ„

<details>
<summary>ç‚¹å‡»å±•å¼€/æŠ˜å </summary>

```mermaid
graph TD;
        __start__([<p>__start__</p>]):::first
        setup_paths(setup_paths)
        handle_error(handle_error)
        run_au_extraction(run_au_extraction)
        save_au_results(save_au_results)
        generate_audio_description(generate_audio_description)
        save_audio_results(save_audio_results)
        generate_video_description(generate_video_description)
        save_video_results(save_video_results)
        extract_full_features(extract_full_features)
        filter_by_emotion(filter_by_emotion)
        find_peak_frame(find_peak_frame)
        generate_peak_frame_visual_description(generate_peak_frame_visual_description)
        generate_peak_frame_au_description(generate_peak_frame_au_description)
        synthesize_summary(synthesize_summary)
        save_mer_results(save_mer_results)
        run_image_analysis(run_image_analysis)
        synthesize_image_summary(synthesize_image_summary)
        save_image_results(save_image_results)
        __end__([<p>__end__</p>]):::last
        __start__ --> setup_paths;
        extract_full_features --> filter_by_emotion;
        filter_by_emotion -.-> find_peak_frame;
        filter_by_emotion -.-> handle_error;
        filter_by_emotion -.-> save_au_results;
        find_peak_frame --> generate_audio_description;
        generate_audio_description -.-> generate_video_description;
        generate_audio_description -.-> handle_error;
        generate_audio_description -.-> save_audio_results;
        generate_peak_frame_au_description --> synthesize_summary;
        generate_peak_frame_visual_description --> generate_peak_frame_au_description;
        generate_video_description -.-> generate_peak_frame_visual_description;
        generate_video_description -.-> handle_error;
        generate_video_description -.-> save_video_results;
        run_au_extraction --> filter_by_emotion;
        run_image_analysis --> synthesize_image_summary;
        setup_paths -. &nbsp;full_pipeline&nbsp; .-> extract_full_features;
        setup_paths -. &nbsp;audio_pipeline&nbsp; .-> generate_audio_description;
        setup_paths -. &nbsp;video_pipeline&nbsp; .-> generate_video_description;
        setup_paths -.-> handle_error;
        setup_paths -. &nbsp;au_pipeline&nbsp; .-> run_au_extraction;
        setup_paths -. &nbsp;image_pipeline&nbsp; .-> run_image_analysis;
        synthesize_image_summary --> save_image_results;
        synthesize_summary --> save_mer_results;
        handle_error --> __end__;
        save_au_results --> __end__;
        save_audio_results --> __end__;
        save_image_results --> __end__;
        save_mer_results --> __end__;
        save_video_results --> __end__;
        classDef default fill:#f2f0ff,line-height:1.2
        classDef first fill-opacity:0
        classDef last fill:#bfb6fc
```

</details>

## ç‰¹æ€§

-   **åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰å¤„ç†æµç¨‹**ï¼šæå–é¢éƒ¨åŠ¨ä½œå•å…ƒï¼ˆAUsï¼‰ï¼Œå¹¶å°†å…¶ç¿»è¯‘æˆæè¿°æ€§çš„è‡ªç„¶è¯­è¨€ã€‚
-   **éŸ³é¢‘åˆ†æå¤„ç†æµç¨‹**ï¼šæå–éŸ³é¢‘ï¼Œè½¬å½•è¯­éŸ³ï¼Œå¹¶è¿›è¡Œè¯¦ç»†çš„éŸ³è°ƒåˆ†æã€‚
-   **è§†é¢‘åˆ†æå¤„ç†æµç¨‹**ï¼šç”Ÿæˆè§†é¢‘å†…å®¹å’Œä¸Šä¸‹æ–‡çš„å…¨é¢æè¿°ã€‚
-   **å›¾åƒåˆ†æå¤„ç†æµç¨‹**ï¼šä¸ºé™æ€å›¾åƒæä¾›ç«¯åˆ°ç«¯çš„æƒ…æ„Ÿè¯†åˆ«ï¼ŒåŒ…æ‹¬è§†è§‰æè¿°å’Œæƒ…æ„Ÿåˆæˆã€‚
-   **å®Œæ•´ MER å¤„ç†æµç¨‹**ï¼šç«¯åˆ°ç«¯çš„å¤šæ¨¡æ€å¤„ç†æµç¨‹ï¼Œè¯†åˆ«æƒ…æ„Ÿå³°å€¼æ—¶åˆ»ï¼Œåˆ†ææ‰€æœ‰æ¨¡æ€ï¼ˆè§†è§‰ã€éŸ³é¢‘ã€é¢éƒ¨ï¼‰ï¼Œå¹¶åˆæˆä¸€ä¸ªæ•´ä½“çš„æƒ…æ„Ÿæ¨ç†æ€»ç»“ã€‚

æŸ¥çœ‹ç¤ºä¾‹è¾“å‡ºï¼š
-   [llava-llama3_llama3.2_merr_data.json](examples/llava-llama3_llama3.2_merr_data.json)
-   [gemini_merr.json](examples/gemini_merr.json)

## å®‰è£…

<p align="center">
  ğŸ“š è¯·è®¿é—® <a href="https://lum1104.github.io/MER-Factory/zh/" target="_blank">é¡¹ç›®æ–‡æ¡£</a> æŸ¥çœ‹è¯¦ç»†çš„å®‰è£…å’Œä½¿ç”¨æ•™ç¨‹ã€‚
</p>

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬å‘½ä»¤ç»“æ„
```bash
python main.py [è¾“å…¥è·¯å¾„] [è¾“å‡ºç›®å½•] [é€‰é¡¹]
```

### ç¤ºä¾‹
```bash
# æŸ¥çœ‹æ‰€æœ‰æ”¯æŒåŠŸèƒ½
python main.py --help

# ä½¿ç”¨ Geminiï¼ˆé»˜è®¤ï¼‰è¿è¡Œå®Œæ•´ MER å¤„ç†æµç¨‹
python main.py path_to_video/ output/ --type MER --silent --threshold 0.8

# ä½¿ç”¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä»£æ›¿æƒ…æ„Ÿè¯†åˆ«
python main.py path_to_video/ output/ --type MER --task "Sentiment Analysis" --silent

# ä½¿ç”¨ ChatGPT æ¨¡å‹
python main.py path_to_video/ output/ --type MER --chatgpt-model gpt-4o --silent

# ä½¿ç”¨æœ¬åœ° Ollama æ¨¡å‹
python main.py path_to_video/ output/ --type MER --ollama-vision-model llava-llama3:latest --ollama-text-model llama3.2 --silent

# ä½¿ç”¨ Hugging Face æ¨¡å‹
python main.py path_to_video/ output/ --type MER --huggingface-model google/gemma-3n-E4B-it --silent

# å¤„ç†å›¾åƒè€Œä¸æ˜¯è§†é¢‘
python main.py ./images ./output --type MER
```

æ³¨æ„ï¼šå¦‚æœéœ€è¦ä½¿ç”¨ Ollama æ¨¡å‹ï¼Œè¯·è¿è¡Œ `ollama pull llama3.2` ç­‰å‘½ä»¤é¢„å…ˆä¸‹è½½æ¨¡å‹ã€‚Ollama ç›®å‰ä¸æ”¯æŒè§†é¢‘åˆ†æã€‚

### æ•°æ®æ•´ç†ä¸è¶…å‚æ•°è°ƒä¼˜ä»ªè¡¨æ¿

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªäº¤äº’å¼ä»ªè¡¨æ¿ç½‘é¡µï¼Œç”¨äºç®€åŒ–æ•°æ®æ•´ç†å’Œè¶…å‚æ•°è°ƒä¼˜è¿‡ç¨‹ã€‚é€šè¿‡è¯¥ä»ªè¡¨æ¿ï¼Œæ‚¨å¯ä»¥æµ‹è¯•ä¸åŒçš„æç¤ºè¯­ï¼Œä¿å­˜å¹¶è¿è¡Œé…ç½®ï¼Œè¿˜å¯ä»¥å¯¹ç”Ÿæˆçš„æ•°æ®è¿›è¡Œè¯„åˆ†ã€‚

è¦å¯åŠ¨ä»ªè¡¨æ¿ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š

```bash
python dashboard.py
```

### å‘½ä»¤è¡Œé€‰é¡¹

| é€‰é¡¹ | ç®€å†™ | æè¿° | é»˜è®¤å€¼ |
|--------|-------|-------------|---------|
| `--type` | `-t` | å¤„ç†ç±»å‹ï¼ˆAUã€audioã€videoã€imageã€MERï¼‰ | MER |
| `--task` | `-tk` | åˆ†æä»»åŠ¡ç±»å‹ï¼ˆEmotion Recognitionã€Sentiment Analysisï¼‰ | Emotion Recognition |
| `--label-file` | `-l` | CSV æ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å« 'name' å’Œ 'label' åˆ—ã€‚å¯é€‰ï¼Œç”¨äºçœŸå®æ ‡ç­¾ã€‚ | None |
| `--threshold` | `-th` | æƒ…æ„Ÿæ£€æµ‹é˜ˆå€¼ï¼ˆ0.0-5.0ï¼‰ | 0.8 |
| `--peak_dis` | `-pd` | æƒ…æ„Ÿå³°å€¼å¸§æ£€æµ‹é—´éš”ï¼ˆæœ€å° 8ï¼‰ | 15 |
| `--silent` | `-s` | ä»¥æœ€å°è¾“å‡ºè¿è¡Œ | False |
| `--cache` | `-ca` | å¤ç”¨ç°æœ‰ éŸ³è§†é¢‘/ AU åˆ†æç»“æœ | False |
| `--concurrency` | `-c` | å¼‚æ­¥å¤„ç†æ–‡ä»¶æ•°é‡ï¼ˆæœ€å° 1ï¼‰ | 4 |
| `--ollama-vision-model` | `-ovm` | Ollama è§†è§‰æ¨¡å‹åç§° | None |
| `--ollama-text-model` | `-otm` | Ollama æ–‡æœ¬æ¨¡å‹åç§° | None |
| `--chatgpt-model` | `-cgm` | ChatGPT æ¨¡å‹åç§°ï¼ˆä¾‹å¦‚ gpt-4oï¼‰ | None |
| `--huggingface-model` | `-hfm` | Hugging Face æ¨¡å‹ ID | None |

### å¤„ç†ç±»å‹

#### 1. åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰æå–
æå–é¢éƒ¨åŠ¨ä½œå•å…ƒå¹¶ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°ï¼š
```bash
python main.py video.mp4 output/ --type AU
```

#### 2. éŸ³é¢‘åˆ†æ
æå–éŸ³é¢‘ï¼Œè½¬å½•è¯­éŸ³å¹¶åˆ†æéŸ³è°ƒï¼š
```bash
python main.py video.mp4 output/ --type audio
```

#### 3. è§†é¢‘åˆ†æ
ç”Ÿæˆè§†é¢‘å†…å®¹çš„å…¨é¢æè¿°ï¼š
```bash
python main.py video.mp4 output/ --type video
```

#### 4. å›¾åƒåˆ†æ
ä½¿ç”¨å›¾åƒè¾“å…¥è¿è¡Œå¤„ç†æµç¨‹ï¼š
```bash
python main.py ./images ./output --type image
# æ³¨æ„ï¼šå›¾åƒæ–‡ä»¶å°†è‡ªåŠ¨ä½¿ç”¨å›¾åƒå¤„ç†æµç¨‹ï¼Œæ— è®º --type è®¾ç½®ä¸ºä½•å€¼
```

#### 5. å®Œæ•´ MER å¤„ç†æµç¨‹ï¼ˆé»˜è®¤ï¼‰
è¿è¡Œå®Œæ•´çš„å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«å¤„ç†æµç¨‹ï¼š
```bash
python main.py video.mp4 output/ --type MER
# æˆ–è€…ç®€å•åœ°ï¼š
python main.py video.mp4 output/
```

### ä»»åŠ¡ç±»å‹

`--task` é€‰é¡¹å…è®¸æ‚¨åœ¨ä¸åŒçš„åˆ†æä»»åŠ¡ä¹‹é—´è¿›è¡Œé€‰æ‹©ï¼š

#### 1. æƒ…æ„Ÿè¯†åˆ«ï¼ˆé»˜è®¤ï¼‰
è¿›è¡Œè¯¦ç»†çš„æƒ…æ„Ÿåˆ†æï¼Œä½¿ç”¨ç²¾ç»†çš„æƒ…æ„Ÿç±»åˆ«ï¼š
```bash
python main.py video.mp4 output/ --task "Emotion Recognition"
# æˆ–è€…ç›´æ¥çœç•¥ --task é€‰é¡¹ï¼Œå› ä¸ºè¿™æ˜¯é»˜è®¤å€¼
python main.py video.mp4 output/
```

#### 2. æƒ…æ„Ÿåˆ†æ
è¿›è¡ŒåŸºäºæƒ…ç»ªææ€§çš„åˆ†æï¼ˆç§¯æã€æ¶ˆæã€ä¸­æ€§ï¼‰ï¼š
```bash
python main.py video.mp4 output/ --task "Sentiment Analysis"
```


### å¯¼å‡ºæ•°æ®é›†

è¦å¯¼å‡ºæ•°æ®é›†ä»¥è¿›è¡Œæ•´ç†æˆ–è®­ç»ƒï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š

#### ç”¨äºæ•°æ®é›†æ•´ç†
```bash
python export.py --output_folder "{output_folder}" --file_type {file_type.lower()} --export_path "{export_path}" --export_csv
```

#### ç”¨äºè®­ç»ƒ
```bash
python export.py --input_csv path/to/csv_file.csv --export_format sharegpt
```

## æ¨¡å‹æ”¯æŒ

è¯¥å·¥å…·æ”¯æŒå››ç§ç±»å‹çš„æ¨¡å‹ï¼š

1. **Google Gemini**ï¼ˆé»˜è®¤ï¼‰ï¼šéœ€è¦åœ¨ `.env` ä¸­é…ç½® `GOOGLE_API_KEY`
2. **OpenAI ChatGPT**ï¼šéœ€è¦åœ¨ `.env` ä¸­é…ç½® `OPENAI_API_KEY`ï¼Œé€šè¿‡ `--chatgpt-model` æŒ‡å®š
3. **Ollama**ï¼šæœ¬åœ°æ¨¡å‹ï¼Œé€šè¿‡ `--ollama-vision-model` å’Œ `--ollama-text-model` æŒ‡å®š
4. **Hugging Face**ï¼šç›®å‰æ”¯æŒç±»ä¼¼ `google/gemma-3n-E4B-it` çš„å¤šæ¨¡æ€æ¨¡å‹

**æ³¨æ„**ï¼šå¦‚æœä½¿ç”¨ Hugging Face æ¨¡å‹ï¼Œä¼šè‡ªåŠ¨å°†å¹¶å‘è®¾ç½®ä¸º 1ï¼Œä»¥å®ç°åŒæ­¥å¤„ç†ã€‚

### æ¨¡å‹æ¨è

#### ä½•æ—¶ä½¿ç”¨ Ollama
**æ¨èç”¨é€”**ï¼šå›¾åƒåˆ†æã€åŠ¨ä½œå•å…ƒåˆ†æã€æ–‡æœ¬å¤„ç†ä»¥åŠç®€å•çš„éŸ³é¢‘è½¬å½•ä»»åŠ¡ã€‚

**ä¼˜åŠ¿**ï¼š
- âœ… **æ”¯æŒå¼‚æ­¥è°ƒç”¨**ï¼šOllama æ”¯æŒå¼‚æ­¥è°ƒç”¨ï¼Œéå¸¸é€‚åˆé«˜æ•ˆå¤„ç†å¤§å‹æ•°æ®é›†
- âœ… **æœ¬åœ°å¤„ç†**ï¼šæ— éœ€ API æˆæœ¬æˆ–é€Ÿç‡é™åˆ¶
- âœ… **ä¸°å¯Œçš„æ¨¡å‹é€‰æ‹©**ï¼šè®¿é—® [ollama.com](https://ollama.com/) äº†è§£å¯ç”¨æ¨¡å‹
- âœ… **éšç§ä¿æŠ¤**ï¼šæ‰€æœ‰å¤„ç†éƒ½åœ¨æœ¬åœ°å®Œæˆ

**ç¤ºä¾‹ç”¨æ³•**ï¼š
```bash
# ä½¿ç”¨ Ollama å¤„ç†å›¾åƒ
python main.py ./images ./output --type image --ollama-vision-model llava-llama3:latest --ollama-text-model llama3.2 --silent

# ä½¿ç”¨ Ollama è¿›è¡Œ AU æå–
python main.py video.mp4 output/ --type AU --ollama-text-model llama3.2 --silent
```

#### ä½•æ—¶ä½¿ç”¨ ChatGPT/Gemini
**æ¨èç”¨é€”**ï¼šé«˜çº§è§†é¢‘åˆ†æã€å¤æ‚çš„å¤šæ¨¡æ€æ¨ç†ä»¥åŠé«˜è´¨é‡å†…å®¹ç”Ÿæˆã€‚

**ä¼˜åŠ¿**ï¼š
- âœ… **æœ€å…ˆè¿›çš„æ€§èƒ½**ï¼šæœ€æ–°çš„ GPT-4o å’Œ Gemini æ¨¡å‹æä¾›å“è¶Šçš„æ¨ç†èƒ½åŠ›
- âœ… **é«˜çº§è§†é¢‘ç†è§£**ï¼šå¯¹å¤æ‚è§†é¢‘åˆ†æå’Œæ—¶é—´æ¨ç†æ”¯æŒæ›´å¥½
- âœ… **é«˜è´¨é‡è¾“å‡º**ï¼šæ›´ç»†è‡´ã€æ›´è¯¦ç»†çš„æƒ…æ„Ÿè¯†åˆ«å’Œæ¨ç†
- âœ… **å¼ºå¤§çš„å¤šæ¨¡æ€é›†æˆ**ï¼šåœ¨æ–‡æœ¬ã€å›¾åƒå’Œè§†é¢‘æ¨¡æ€ä¸Šè¡¨ç°ä¼˜å¼‚

**ç¤ºä¾‹ç”¨æ³•**ï¼š
```bash
python main.py video.mp4 output/ --type MER --chatgpt-model gpt-4o --silent

python main.py video.mp4 output/ --type MER --silent
```

**æƒè¡¡**ï¼šå­˜åœ¨ API æˆæœ¬å’Œé€Ÿç‡é™åˆ¶ï¼Œä½†é€šå¸¸ä¸ºå¤æ‚çš„æƒ…æ„Ÿæ¨ç†ä»»åŠ¡æä¾›æœ€é«˜è´¨é‡çš„ç»“æœã€‚

#### ä½•æ—¶ä½¿ç”¨ Hugging Face æ¨¡å‹
**æ¨èç”¨é€”**ï¼šå½“æ‚¨éœ€è¦æœ€æ–°çš„æœ€å…ˆè¿›çš„æ¨¡å‹æˆ– Ollama ä¸æ”¯æŒçš„ç‰¹å®šåŠŸèƒ½æ—¶ã€‚

**è‡ªå®šä¹‰æ¨¡å‹é›†æˆ**ï¼š
å¦‚æœæ‚¨æƒ³ä½¿ç”¨æœ€æ–°çš„ Hugging Face æ¨¡å‹æˆ– Ollama ä¸æ”¯æŒçš„åŠŸèƒ½ï¼š

1. **é€‰é¡¹ 1 - è‡ªè¡Œå®ç°**ï¼šå¯¼èˆªè‡³ `mer_factory/models/hf_models/__init__.py`ï¼ŒæŒ‰ç…§ç°æœ‰æ¨¡å¼æ³¨å†Œæ‚¨çš„æ¨¡å‹å¹¶å®ç°æ‰€éœ€åŠŸèƒ½ã€‚

2. **é€‰é¡¹ 2 - è¯·æ±‚æ”¯æŒ**ï¼šåœ¨æˆ‘ä»¬çš„ä»“åº“ä¸­æäº¤é—®é¢˜ï¼Œå‘Šè¯‰æˆ‘ä»¬æ‚¨å¸Œæœ›æˆ‘ä»¬æ”¯æŒçš„æ¨¡å‹ï¼Œæˆ‘ä»¬ä¼šè€ƒè™‘æ·»åŠ ã€‚

**å½“å‰æ”¯æŒçš„æ¨¡å‹**ï¼š`google/gemma-3n-E4B-it` ä»¥åŠå…¶ä»–åœ¨ HF æ¨¡å‹ç›®å½•ä¸­åˆ—å‡ºçš„æ¨¡å‹ã€‚

## å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶æˆ–é¡¹ç›®ä¸­å‘ç° MER-Factory å¾ˆæœ‰ç”¨ï¼Œè¯·è€ƒè™‘å¼•ç”¨æˆ‘ä»¬ï¼š

```bibtex
@software{Lin_MER-Factory_2025,
  author = {Lin, Yuxiang and Zheng, Shunchao},
  doi = {10.5281/zenodo.15847351},
  license = {MIT},
  month = {7},
  title = {{MER-Factory}},
  url = {https://lum1104.github.io/MER-Factory/},
  version = {0.1.0},
  year = {2025}
}
```
